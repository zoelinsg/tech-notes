# 負責任的AI應用
## 🌟 課程使用 AI 工具
- DB ranking：https://db-engines.com/en/ranking
- Colab：https://colab.google/

### 📌 什麼是負責任 AI？
- 負責任 AI 是一種強調「道德、透明、安全、公平」的 AI 開發與應用方式。
    - **核心價值**：安全、可靠、公平、透明、可解釋、具責任性。
    - **實踐面向**：不僅是技術創新，也需結合法律、政策與倫理層面。
    - **範疇應用**：經濟（避免壟斷）、環境（減少資源消耗）、社會（促進公平）。

### 🧠 為什麼需要負責任 AI？
- **信任與接受度**：AI 若帶有偏見或決策不透明，容易失去用戶信任。
- **防止傷害**：不當應用 AI 容易擴大社會不公與歧視。
- **法律與合規**：各國政府日益重視 AI 的監管與問責框架。

### 🧪 負責任 AI 六大原則（以 Microsoft 為例）
1. **公平性（Fairness）**：
    - 避免模型因性別、年齡、種族等造成差別待遇。
    - 評估指標：效能差異、選取率差異。
2. **可靠性與安全性（Reliability & Safety）**：
    - 模型在非預期場景仍能穩定運行，不會產生有害結果。
    - 工具：錯誤分析、異常資料偵測。
3. **隱私與保密性（Privacy & Security）**：
    - 遵循隱私法規（如 GDPR），提供用戶數據控制權與加密保護。
4. **包容性（Inclusiveness）**：
    - AI 設計考慮不同使用者情境與限制，例如語音提示、無障礙功能。
5. **透明度（Transparency）**：
    - 模型與決策應可解釋與追蹤。
    - 技術工具：模型可解釋性（InterpretML）、反事實分析。
6. **責任性（Accountability）**：
    - 開發者需對 AI 行為與結果負責。
    - 實踐方法：MLOps 流程記錄（模型註冊、事件通知、運營監控）。

### 📊 負責任 AI 儀表板（RAI Dashboard）
- 整合模型公平性評量、資料探索、模型可解釋性、錯誤分析、反事實分析、原因推斷。
- 支援 DevOps / MLOps 流程，有助模型偵錯與部署決策。
- Azure ML 提供完整工具鏈整合。

### 🧯 常見風險與緩解方式
| 類型 | 說明 | 緩解方式 |
| --- | --- | --- |
| 配置損害 | 特定族群在選取機會中被低估（如求職、貸款） | 使用群組公平性評估、選取率計量 |
| 服務品質損害 | 某些群體模型表現較差（如語音識別） | 差異量化分析、錯誤熱圖診斷 |
| 資安風險 | 敏感資料外洩或存取控制失效 | 資料加密與稽核、網路存取管控 |
| 可解釋性不足 | 使用者不理解預測來源與依據 | 模型全域/局部說明、反事實推理 |

### 📊 負責任 AI 儀表板（RAI Dashboard）
- Azure ML 中的 RAI 儀表板是一套整合工具組，幫助開發者以數據為基礎進行模型評估與調試。它提供一個統一介面進行以下任務：
    - 識別模型錯誤與公平性問題
    - 診斷錯誤發生原因
    - 進行風險通知與降低措施
    - 評估與偵錯機器學習模型性能
- 儀表板元件概覽：
    - 資料探索器（Data Explorer）
    - 錯誤分析（Error Analysis）
    - 模型概覽（Model Overview）
    - 公平性評量（Fairness Assessment）
    - 模型可解釋性（Model Interpretability）
    - 原因推斷（Causal Inference）
    - 反事實分析（Counterfactual Analysis）
- 模型偵錯三階段：
    1. **識別問題**
    2. **診斷原因**
    3. **採取風險緩解措施**

### 🔍 錯誤分析工具
- 幫助開發者快速識別錯誤群體與根本原因：
    - **錯誤群體識別**：使用決策樹或錯誤熱圖定位高錯誤率的群體。
    - **錯誤診斷**：整體與局部預測、假設分析等手段了解模型行為。

### 🧭 資料探索與結構理解
- 檢查數據完整性、一致性與準確性，是模型可靠性的前提。
- 深入了解資料分佈與特徵，幫助模型設計、清理與效能優化。
- 資料結構組成包括：
    - 類型（整數、字串等）、欄位、記錄、索引、關聯性

### 🎯 模型概覽與公平性評量
- **模型概覽**：總結模型評估指標與敏感群體效能差異。
- **公平性評量**：詳細分析模型在性別、種族等群體的行為，揭示偏見與進行調整。

### 💬 可解釋性與原因推斷
- **InterpretML** 工具提供整體與個別預測解釋、特徵影響與假設分析。
- **EconML** 支援因果推論分析，針對控制變數推估特定因素對結果的影響。

### 🔁 反事實分析與微擾測試
- **反事實分析**：生成與當前樣本微小差異的樣本來觀察預測改變，揭示模型敏感特徵與偏誤。
- **微擾測試**：系統化地改變特徵值以檢查模型穩定性，例如調整產品參數觀察市場反應。